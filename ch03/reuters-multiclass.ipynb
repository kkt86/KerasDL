{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index <-> word mappings\n",
    "word_index = reuters.get_word_index()\n",
    "reversed_word_index = dict([(value, key) for key, value in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([reversed_word_index.get(i-3, \"?\") for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    result = np.zeros(( len(sequences), dimension))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        result[i, seq] = 1\n",
    "    return result\n",
    "\n",
    "train_x = vectorize_sequences(train_data)\n",
    "test_x = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encode labels\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "from keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000, )))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = train_x[:1000]\n",
    "x_partial_train = train_x[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "y_partial_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 2.5081 - acc: 0.4935 - val_loss: 1.6759 - val_acc: 0.6470\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 1.3942 - acc: 0.7036 - val_loss: 1.3148 - val_acc: 0.7010\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 0s 57us/step - loss: 1.0582 - acc: 0.7754 - val_loss: 1.1330 - val_acc: 0.7580\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.8352 - acc: 0.8261 - val_loss: 1.0218 - val_acc: 0.7910\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.6609 - acc: 0.8612 - val_loss: 0.9647 - val_acc: 0.7960\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.5304 - acc: 0.8890 - val_loss: 0.8988 - val_acc: 0.8190\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.4199 - acc: 0.9112 - val_loss: 0.9233 - val_acc: 0.7940\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.3393 - acc: 0.9250 - val_loss: 0.8783 - val_acc: 0.8170\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.2853 - acc: 0.9367 - val_loss: 0.8832 - val_acc: 0.8130\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.2362 - acc: 0.9449 - val_loss: 0.9064 - val_acc: 0.8080\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.2053 - acc: 0.9489 - val_loss: 0.9213 - val_acc: 0.8150\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1852 - acc: 0.9514 - val_loss: 0.9118 - val_acc: 0.8090\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 0s 59us/step - loss: 0.1589 - acc: 0.9536 - val_loss: 0.9577 - val_acc: 0.8130\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1483 - acc: 0.9544 - val_loss: 0.9770 - val_acc: 0.8010\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1409 - acc: 0.9555 - val_loss: 0.9474 - val_acc: 0.8190\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1309 - acc: 0.9569 - val_loss: 1.0135 - val_acc: 0.7990\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1237 - acc: 0.9573 - val_loss: 1.0674 - val_acc: 0.7900\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1211 - acc: 0.9573 - val_loss: 1.0532 - val_acc: 0.7960\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 0s 60us/step - loss: 0.1173 - acc: 0.9574 - val_loss: 1.0544 - val_acc: 0.7990\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 0s 58us/step - loss: 0.1064 - acc: 0.9593 - val_loss: 1.0308 - val_acc: 0.8090\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_partial_train, y_partial_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
